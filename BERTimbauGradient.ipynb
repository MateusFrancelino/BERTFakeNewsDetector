{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification,TrainingArguments,Trainer, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4200\n",
      "Validation size: 1400\n",
      "Testing size: 1400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3886</th>\n",
       "      <td>Lula ataca a PF,  o Judiciário,  o MP,  a mídi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>966</th>\n",
       "      <td>Hacker afirma que Lula tinha celular: \"Eu entr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5622</th>\n",
       "      <td>Teatro Municipal do Rio recebe show evangélico...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6373</th>\n",
       "      <td>9 vezes em que a publicidade falhou em entende...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>Prisão de Lula pode ser o desejo de muitos, ma...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020</th>\n",
       "      <td>Governo afasta diretores e conselheiros do Pos...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6781</th>\n",
       "      <td>Mandando pra geral. O historiador Flávio de Ca...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>667</th>\n",
       "      <td>Dilma será notificada nesta manhã e Temer assu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6176</th>\n",
       "      <td>Contracheque de Lula mostrando \"aposentadoria ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3555</th>\n",
       "      <td>Sem governo,  sem ministério e sem foro privil...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "3886  Lula ataca a PF,  o Judiciário,  o MP,  a mídi...      1\n",
       "966   Hacker afirma que Lula tinha celular: \"Eu entr...      1\n",
       "5622  Teatro Municipal do Rio recebe show evangélico...      0\n",
       "6373  9 vezes em que a publicidade falhou em entende...      0\n",
       "1793  Prisão de Lula pode ser o desejo de muitos, ma...      0\n",
       "...                                                 ...    ...\n",
       "2020  Governo afasta diretores e conselheiros do Pos...      0\n",
       "6781  Mandando pra geral. O historiador Flávio de Ca...      0\n",
       "667   Dilma será notificada nesta manhã e Temer assu...      0\n",
       "6176  Contracheque de Lula mostrando \"aposentadoria ...      1\n",
       "3555  Sem governo,  sem ministério e sem foro privil...      1\n",
       "\n",
       "[4200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5553</th>\n",
       "      <td>Renan Calheiros disse para Gleisi: \"Eu desfiz ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6845</th>\n",
       "      <td>Mãe de vítima de feminicídio no ES faz alerta ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2224</th>\n",
       "      <td>Medo de morrer, de matar e de se contaminar: t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>Deus mandou votar a favor de Temer, disseram...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Desembargador manda recado ao povo: \"É hora de...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6877</th>\n",
       "      <td>STF não comenta vazamento e informa que Fachin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>Datena manda recado para a Rede Globo: \"Oportu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6037</th>\n",
       "      <td>Bumlai entrega Lula: \"Fui obrigado a fazer um ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5421</th>\n",
       "      <td>Quem foi Giordano Bruno, o místico visionário ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4310</th>\n",
       "      <td>Com microfone aberto,  deputado deixa escapar:...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "5553  Renan Calheiros disse para Gleisi: \"Eu desfiz ...      1\n",
       "6845  Mãe de vítima de feminicídio no ES faz alerta ...      0\n",
       "2224  Medo de morrer, de matar e de se contaminar: t...      0\n",
       "595   Deus mandou votar a favor de Temer, disseram...      1\n",
       "37    Desembargador manda recado ao povo: \"É hora de...      1\n",
       "...                                                 ...    ...\n",
       "6877  STF não comenta vazamento e informa que Fachin...      0\n",
       "1604  Datena manda recado para a Rede Globo: \"Oportu...      1\n",
       "6037  Bumlai entrega Lula: \"Fui obrigado a fazer um ...      1\n",
       "5421  Quem foi Giordano Bruno, o místico visionário ...      0\n",
       "4310  Com microfone aberto,  deputado deixa escapar:...      1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6204</th>\n",
       "      <td>Lava Jato: defesa de Bendine pede que incompet...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5904</th>\n",
       "      <td>Menina de 16 anos que motivou campanha na web ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>URGENTE: Janot pede prisão de Aécio Neves. O p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2823</th>\n",
       "      <td>efesa de Lula reitera pedido para que ex-presi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3501</th>\n",
       "      <td>De que lado eles estão? Navios russos e chines...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3888</th>\n",
       "      <td>A força-tarefa da Operação Lava Jato em Curiti...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2627</th>\n",
       "      <td>Temer prevê reforma da Previdência concluída a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4335</th>\n",
       "      <td>‘Manter o discurso de golpe é impróprio ao Paí...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1680</th>\n",
       "      <td>João Santana e Mônica Moura depõem em ação sob...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6271</th>\n",
       "      <td>Juiz Sérgio Moro divulga nota contra a ANISTIA...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "6204  Lava Jato: defesa de Bendine pede que incompet...      0\n",
       "5904  Menina de 16 anos que motivou campanha na web ...      0\n",
       "181   URGENTE: Janot pede prisão de Aécio Neves. O p...      1\n",
       "2823  efesa de Lula reitera pedido para que ex-presi...      0\n",
       "3501  De que lado eles estão? Navios russos e chines...      1\n",
       "...                                                 ...    ...\n",
       "3888  A força-tarefa da Operação Lava Jato em Curiti...      0\n",
       "2627  Temer prevê reforma da Previdência concluída a...      0\n",
       "4335  ‘Manter o discurso de golpe é impróprio ao Paí...      0\n",
       "1680  João Santana e Mônica Moura depõem em ação sob...      0\n",
       "6271  Juiz Sérgio Moro divulga nota contra a ANISTIA...      1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CSV_PATH = \"C:\\TCC\\Base\\merged_data.csv\" \n",
    "\n",
    "# Carregar dados do CSV usando pandas\n",
    "data = pd.read_csv(CSV_PATH, sep='|', usecols=[\"text\",\"category\",\"label\"])\n",
    "data[\"text\"] = data[\"text\"].str.replace('\\n', ' ').replace('\\t', ' ').replace('   ', ' ').replace('  ', ' ')\n",
    "data = shuffle(data).reset_index(drop=True)\n",
    "\n",
    "original_label_dtype = data['label'].dtype\n",
    "data['label'] = data['label'].astype(str)\n",
    "\n",
    "data['stratify_col'] = data['category'] + '-' + data['label']\n",
    "\n",
    "data.drop('category', axis=1, inplace=True)\n",
    "data['label'] = data['label'].astype(original_label_dtype)\n",
    "\n",
    "#(60%)(20%)(20%)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.4, stratify=data['stratify_col'], random_state=42)\n",
    "validate_data, test_data = train_test_split(temp_data, test_size=0.5, stratify=temp_data['stratify_col'], random_state=42)\n",
    "\n",
    "train_data.drop('stratify_col', axis=1, inplace=True)\n",
    "validate_data.drop('stratify_col', axis=1, inplace=True)\n",
    "test_data.drop('stratify_col', axis=1, inplace=True)\n",
    "\n",
    "print(\"Training size: {}\".format(len(train_data)))\n",
    "print(\"Validation size: {}\".format(len(validate_data)))\n",
    "print(\"Testing size: {}\".format(len(test_data)))\n",
    "\n",
    "display(train_data)\n",
    "display(validate_data)\n",
    "display(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "validate_data = validate_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4200\n",
      "Validation size: 1400\n",
      "Testing size: 1400\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size: {}\".format(len(train_data)))\n",
    "print(\"Validation size: {}\".format(len(validate_data)))\n",
    "print(\"Testing size: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escolhendo a GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", from_tf=True)\n",
    "model.config.num_labels = 1\n",
    "#load no Tokenizador e o modelo BERTimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # #Desabilitando a atualização dos gradientes para acelerar o processamento e diminuir o consumo\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a arquitetura da camada classificadora\n",
    "# composta por várias camadas densas e de ativação para processamento não linear e uma camada Softmax \n",
    "# para obter as probabilidades de cada classe.\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(768, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 2),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# Alocando o modelo e o critério de perda na GPU\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "# Atualizar apenas os parâmetros da camada classificadora com uma taxa de aprendizado de 0,01.\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  #limpando String\n",
    "  return text.replace('\\n', ' ').replace('\\t', ' ').replace('   ', ' ').replace('  ', ' ')\n",
    " \n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    parts = []\n",
    "\n",
    "    text_len = len(text.split(' '))\n",
    "    delta = 300 #numero de palavras\n",
    "    max_parts = 5 #numero maximo de partes a serem divididas\n",
    "    nb_cuts = int(text_len / delta)\n",
    "    nb_cuts = min(nb_cuts, max_parts)\n",
    "    \n",
    "    #Tokenizando o texto\n",
    "    for i in range(nb_cuts + 1):\n",
    "        text_part = ' '.join(text.split(' ')[i * delta: (i + 1) * delta])\n",
    "        parts.append(tokenizer.encode(text_part, return_tensors=\"pt\", max_length=500).to(device))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def testText(text):\n",
    "    text_parts = preprocess_text(text)\n",
    "    overall_output = torch.zeros((1,2)).to(device)\n",
    "    try:\n",
    "        for part in text_parts:\n",
    "            if len(part) > 0:\n",
    "                overall_output += model(part.reshape(1, -1))[0]\n",
    "    except RuntimeError:\n",
    "        print(\"GPU out of memory, skipping this entry.\")\n",
    "\n",
    "    overall_output = F.softmax(overall_output[0], dim=-1)\n",
    "\n",
    "    value, result = overall_output.max(0)\n",
    "\n",
    "    term = \"falso\"\n",
    "    if result.item() == 0:\n",
    "        term = \"verdadeiro\"\n",
    "\n",
    "    print(\"{} : {}%\".format(term, value.item() * 100))\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertFakeNewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_seq_length=512):\n",
    "        self._labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
    "        self._encodings = {\"input_ids\": [],\n",
    "                           \"token_type_ids\": [],\n",
    "                           \"attention_mask\": []}\n",
    "\n",
    "        for txt in df[\"text\"].values:\n",
    "            enc_dict = tokenizer.encode_plus(\n",
    "                text=txt,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_seq_length,\n",
    "                return_token_type_ids=True,\n",
    "                padding=\"max_length\",\n",
    "                return_attention_mask=True,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "            )\n",
    "            # Verifica se a parte tokenizada excede o limite após adicionar tokens especiais\n",
    "            if len(enc_dict[\"input_ids\"][0]) > max_seq_length:\n",
    "                print(\"Truncamento detectado após adição de tokens especiais!\")\n",
    "\n",
    "            for k, v in enc_dict.items():\n",
    "                self._encodings[k].append(v[0])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: value[idx] for key, value in self._encodings.items()}\n",
    "        item[\"labels\"] = self._labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataTK = BertFakeNewsDataset(train_data,tokenizer)\n",
    "validate_dataTK = BertFakeNewsDataset(validate_data,tokenizer)\n",
    "test_dataTK = BertFakeNewsDataset(test_data,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"qwk\": cohen_kappa_score(labels, predictions, weights=\"quadratic\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir='C:\\TCC',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2.5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=1e-5, #1e-5 ou 5e-5 é um valor padrão 0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataTK,\n",
    "    eval_dataset=validate_dataTK,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/2630 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "                                                       \n",
      " 10%|█         | 263/2630 [1:24:27<9:40:35, 14.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32486164569854736, 'eval_accuracy': 0.9907142857142858, 'eval_qwk': 0.9814286472300113, 'eval_runtime': 279.2336, 'eval_samples_per_second': 5.014, 'eval_steps_per_second': 0.315, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 500/2630 [2:36:33<10:47:21, 18.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3603, 'learning_rate': 2.0247148288973387e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 20%|██        | 526/2630 [2:48:54<8:35:46, 14.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3368585705757141, 'eval_accuracy': 0.9764285714285714, 'eval_qwk': 0.9528592593801911, 'eval_runtime': 279.3185, 'eval_samples_per_second': 5.012, 'eval_steps_per_second': 0.315, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 30%|███       | 789/2630 [4:13:21<7:31:01, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32147619128227234, 'eval_accuracy': 0.9914285714285714, 'eval_qwk': 0.9828567580088533, 'eval_runtime': 279.2021, 'eval_samples_per_second': 5.014, 'eval_steps_per_second': 0.315, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1000/2630 [5:17:32<8:15:29, 18.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3233, 'learning_rate': 1.549429657794677e-05, 'epoch': 3.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 40%|████      | 1052/2630 [5:37:48<6:26:42, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3201983571052551, 'eval_accuracy': 0.9928571428571429, 'eval_qwk': 0.9857142565597072, 'eval_runtime': 279.1266, 'eval_samples_per_second': 5.016, 'eval_steps_per_second': 0.315, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 50%|█████     | 1315/2630 [7:02:14<5:22:13, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32117804884910583, 'eval_accuracy': 0.9921428571428571, 'eval_qwk': 0.9842859067031833, 'eval_runtime': 279.3471, 'eval_samples_per_second': 5.012, 'eval_steps_per_second': 0.315, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1500/2630 [7:58:30<5:43:39, 18.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3178, 'learning_rate': 1.0741444866920153e-05, 'epoch': 5.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \n",
      " 60%|██████    | 1578/2630 [8:26:40<4:17:44, 14.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3289737403392792, 'eval_accuracy': 0.9842857142857143, 'eval_qwk': 0.9685726471830685, 'eval_runtime': 279.1364, 'eval_samples_per_second': 5.015, 'eval_steps_per_second': 0.315, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 70%|███████   | 1841/2630 [9:53:13<3:25:16, 15.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32312193512916565, 'eval_accuracy': 0.99, 'eval_qwk': 0.9800002857102041, 'eval_runtime': 303.3756, 'eval_samples_per_second': 4.615, 'eval_steps_per_second': 0.29, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 2000/2630 [10:44:55<3:26:40, 19.68s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3178, 'learning_rate': 5.988593155893536e-06, 'epoch': 7.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                        \n",
      " 80%|████████  | 2104/2630 [11:24:12<2:20:57, 16.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3218643069267273, 'eval_accuracy': 0.9914285714285714, 'eval_qwk': 0.9828573177824717, 'eval_runtime': 308.2273, 'eval_samples_per_second': 4.542, 'eval_steps_per_second': 0.286, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \n",
      " 90%|█████████ | 2367/2630 [12:53:20<1:05:44, 15.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.32111856341362, 'eval_accuracy': 0.9921428571428571, 'eval_qwk': 0.9842859067031833, 'eval_runtime': 285.8987, 'eval_samples_per_second': 4.897, 'eval_steps_per_second': 0.308, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2500/2630 [13:35:17<39:28, 18.22s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.3161, 'learning_rate': 1.2357414448669203e-06, 'epoch': 9.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                      \n",
      "100%|██████████| 2630/2630 [14:20:35<00:00, 16.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.31972524523735046, 'eval_accuracy': 0.9935714285714285, 'eval_qwk': 0.9871429620982686, 'eval_runtime': 303.3819, 'eval_samples_per_second': 4.615, 'eval_steps_per_second': 0.29, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2630/2630 [14:20:37<00:00, 19.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 51637.9671, 'train_samples_per_second': 0.813, 'train_steps_per_second': 0.051, 'train_loss': 0.32649638099815453, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2630, training_loss=0.32649638099815453, metrics={'train_runtime': 51637.9671, 'train_samples_per_second': 0.813, 'train_steps_per_second': 0.051, 'train_loss': 0.32649638099815453, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [15:20<00:00,  3.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.31543150544166565,\n",
       " 'eval_accuracy': 0.9978571428571429,\n",
       " 'eval_qwk': 0.9957142857142857,\n",
       " 'eval_runtime': 925.0628,\n",
       " 'eval_samples_per_second': 4.54,\n",
       " 'eval_steps_per_second': 0.284,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_dataTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [05:06<00:00,  3.48s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.31972524523735046,\n",
       " 'eval_accuracy': 0.9935714285714285,\n",
       " 'eval_qwk': 0.9871429620982686,\n",
       " 'eval_runtime': 310.3966,\n",
       " 'eval_samples_per_second': 4.51,\n",
       " 'eval_steps_per_second': 0.284,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(validate_dataTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [05:07<00:00,  3.50s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3177434802055359,\n",
       " 'eval_accuracy': 0.995,\n",
       " 'eval_qwk': 0.9899999183666806,\n",
       " 'eval_runtime': 311.8541,\n",
       " 'eval_samples_per_second': 4.489,\n",
       " 'eval_steps_per_second': 0.282,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataTK) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falso : 88.0777895450592%\n",
      "verdadeiro : 73.10200333595276%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'verdadeiro'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falso = \"\"\"Mais uma pérola da \"senhora que estoca vento\". Em nota, ela sugere que a PF \"tortura\" investigados.  A ex-presidente impeachmada Dilma Rousseff continua falando pelos cotovelos.  (observação: Em seu texto, ela não usou a palavra \"tortura\" [...] mas para quem sabe ler, um pingo é letra!) Durante a última semana, Dilma teve a audácia (a petulância, a ousadia, destemor) de dizer que os investigadores da Polícia Federal estão ameaçando os delatores da Lava-Jato. Dilma também atacou o ministro relator da Lava-Jato, Edson Fachin, e o acusou de abrir as delações de João Santana e Mônica Moura para a imprensa antes sem antes dar acesso dos documentos a seus advogados. Resumindo, Dilma é honesta [...] já Edson Fachin (Ministro do STF) e a Polícia Federal são os \"bandidos da história\" Em uma nota divulgada na última sexta-feira, a \"senhora que estoca vento\" também disse que todos os delatores são mentirosos. abaixo a íntegra da nota: 1. Infelizmente, chega tarde a decisão do relator da Lava Jato no Supremo Tribunal Federal, ministro Edson Fachin, suspendendo o sigilo dos depoimentos de João Santana e Monica Moura. 2. Há semanas, a defesa da presidenta eleita Dilma Rousseff havia feito tal pedido ao Tribunal Superior Eleitoral, a fim de apresentar suas alegações finais ao relator do caso das contas de campanha, ministro Herman Benjamin. 3. A defesa foi prejudicada pela negativa do relator. Não foi possível cotejar os depoimentos prestados pelo casal à Justiça Eleitoral e na Lava Jato. 4. As contradições e falsos testemunhos foram vislumbrados, apesar disso, pelo que foi divulgado amplamente pela imprensa, na velha estratégia do vazamento seletivo dos depoimentos – uma rotina nos últimos tempos. 5. Agora mesmo, os depoimentos são entregues à imprensa, mas não repassados oficialmente à defesa da presidente eleita. 6. Dilma Rousseff, contudo, reitera o que apontou antes: João Santana e Monica Moura prestaram falso testemunho e faltaram com a verdade em seus depoimentos, provavelmente pressionados pelas ameaças dos investigadores. 7. Apesar de tudo, a presidente eleita acredita na Justiça e sabe que a verdade virá à tona e será restabelecida.\"\"\"\n",
    "\n",
    "Verdadeiro = \"\"\"Saúde de Lula é 'excelente', atestam exames feitos hoje\n",
    "\n",
    "O ex-presidente Luiz Inácio Lula da Silva encontra-se em \"excelente condição de saúde e sem qualquer evidência de neoplasia\", diz o boletim assinado pelos médicos Antonio Carlos Onofre de Lira, diretor técnico médico, e Paulo Cesar Ayroza Galvão, diretor clínico do hospital sírio-libanês.\n",
    "\n",
    "Lula foi submetido a exames clínicos, laboratoriais, PET-CT, ressonância nuclear magnética e laringoscopia durante toda a manhã deste sábado, 1. Todos de rotina. Essa rotina vem sendo repetida desde 2011, quando foi detectado um câncer na laringe do ex-presidente, que se submeteu a tratamento e deve fazer o controle por cinco anos. O último exame havia sido realizado em 10 de agosto. As equipes que acompanham o ex-presidente são coordenadas pelos médicos Roberto Kalil Filho e Artur Katz. Lula deixou o hospital sem falar com a imprensa.\n",
    "\"\"\"\n",
    "\n",
    "testText(falso)\n",
    "testText(Verdadeiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [04:57<00:00,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9949820788530466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Obter as previsões do modelo para o conjunto de teste\n",
    "predictions = trainer.predict(test_dataTK).predictions\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obter os rótulos verdadeiros do conjunto de teste\n",
    "true_labels = test_dataTK._labels.numpy()\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"C:\\ModeloTurbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
