{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import re\n",
    "\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import cohen_kappa_score, accuracy_score\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertModel, AdamW, get_linear_schedule_with_warmup, BertForSequenceClassification,TrainingArguments,Trainer, AutoTokenizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4200\n",
      "Validation size: 1400\n",
      "Testing size: 1400\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3803</th>\n",
       "      <td>Lula diz que Dória quer se projetar às custas ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>Maracutaia nas indicações da Petrobras? Delato...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5336</th>\n",
       "      <td>Ex-policial acusado de liderar grupo de exterm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6434</th>\n",
       "      <td>O bombeiro herói que há três décadas salva pes...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>Com 'textão', William Bonner denuncia seguidor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2112</th>\n",
       "      <td>O habeas corpus preventivo de Lula e a continu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6760</th>\n",
       "      <td>Expectativa de vida do paranaense ao nascer fo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>É importante que a população saiba a situação ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>Delator da Lava-Jato vai cumprir pena em mansã...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3513</th>\n",
       "      <td>Tiririca pretende se candidatar a presidência ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4200 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "3803  Lula diz que Dória quer se projetar às custas ...      1\n",
       "915   Maracutaia nas indicações da Petrobras? Delato...      1\n",
       "5336  Ex-policial acusado de liderar grupo de exterm...      0\n",
       "6434  O bombeiro herói que há três décadas salva pes...      0\n",
       "1808  Com 'textão', William Bonner denuncia seguidor...      0\n",
       "...                                                 ...    ...\n",
       "2112  O habeas corpus preventivo de Lula e a continu...      0\n",
       "6760  Expectativa de vida do paranaense ao nascer fo...      0\n",
       "752   É importante que a população saiba a situação ...      0\n",
       "6202  Delator da Lava-Jato vai cumprir pena em mansã...      1\n",
       "3513  Tiririca pretende se candidatar a presidência ...      1\n",
       "\n",
       "[4200 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5554</th>\n",
       "      <td>Presidente das Filipinas mostra como lidar com...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6889</th>\n",
       "      <td>Movimentos sociais protocolam pedido de abertu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2269</th>\n",
       "      <td>Filme Arábia mostra força da vida pacata no 50...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>Maduro compara governo brasileiro ao narcotráf...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>No Fórum Econômico de Davos,  doze soldados do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6882</th>\n",
       "      <td>FHC depõe como testemunha, diz que acervo tem ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>Esposa de ditador comunista maluco faz rara ap...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6048</th>\n",
       "      <td>Contrato do \"ap\" de Lula no Guarujá foi rasura...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5695</th>\n",
       "      <td>Agressões em casa, discriminação e risco de mo...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4287</th>\n",
       "      <td>Joesley: \"Nóis vai virá amigo desse Janot. Nin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "5554  Presidente das Filipinas mostra como lidar com...      1\n",
       "6889  Movimentos sociais protocolam pedido de abertu...      0\n",
       "2269  Filme Arábia mostra força da vida pacata no 50...      0\n",
       "503   Maduro compara governo brasileiro ao narcotráf...      1\n",
       "39    No Fórum Econômico de Davos,  doze soldados do...      1\n",
       "...                                                 ...    ...\n",
       "6882  FHC depõe como testemunha, diz que acervo tem ...      0\n",
       "1662  Esposa de ditador comunista maluco faz rara ap...      1\n",
       "6048  Contrato do \"ap\" de Lula no Guarujá foi rasura...      1\n",
       "5695  Agressões em casa, discriminação e risco de mo...      0\n",
       "4287  Joesley: \"Nóis vai virá amigo desse Janot. Nin...      1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6245</th>\n",
       "      <td>Sete ministros que vão disputar eleição só que...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6052</th>\n",
       "      <td>Repercussão da Carne Fraca nas finanças da BRF...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>Mais um grampo! Senador do PT é flagrado chama...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>Nos ajudem a ajudar vocês, diz Padilha a apose...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3342</th>\n",
       "      <td>Gás de cozinha terá novo aumento a partir de a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>A decisão eu respeito, o que não aceito é a me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>BRASÍLIA - Dentro do carro, em silêncio profun...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4456</th>\n",
       "      <td>Amigos se despedem do jornalista Jorge Bastos ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1714</th>\n",
       "      <td>Hamas convoca nova intifada após anúncio de Tr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6273</th>\n",
       "      <td>Dilma surta no Facebook e reclama de não poder...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1400 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  label\n",
       "6245  Sete ministros que vão disputar eleição só que...      0\n",
       "6052  Repercussão da Carne Fraca nas finanças da BRF...      0\n",
       "143   Mais um grampo! Senador do PT é flagrado chama...      1\n",
       "2911  Nos ajudem a ajudar vocês, diz Padilha a apose...      0\n",
       "3342  Gás de cozinha terá novo aumento a partir de a...      1\n",
       "...                                                 ...    ...\n",
       "3986  A decisão eu respeito, o que não aceito é a me...      0\n",
       "2686  BRASÍLIA - Dentro do carro, em silêncio profun...      0\n",
       "4456  Amigos se despedem do jornalista Jorge Bastos ...      0\n",
       "1714  Hamas convoca nova intifada após anúncio de Tr...      0\n",
       "6273  Dilma surta no Facebook e reclama de não poder...      1\n",
       "\n",
       "[1400 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "CSV_PATH = \"C:\\TCC\\Base\\merged_data.csv\" \n",
    "\n",
    "# Carregar dados do CSV usando pandas\n",
    "data = pd.read_csv(CSV_PATH, sep='|', usecols=[\"text\",\"category\",\"label\"])\n",
    "data[\"text\"] = data[\"text\"].str.replace('\\n', ' ').replace('\\t', ' ').replace('   ', ' ').replace('  ', ' ')\n",
    "data = shuffle(data).reset_index(drop=True)\n",
    "\n",
    "original_label_dtype = data['label'].dtype\n",
    "data['label'] = data['label'].astype(str)\n",
    "\n",
    "data['stratify_col'] = data['category'] + '-' + data['label']\n",
    "\n",
    "data.drop('category', axis=1, inplace=True)\n",
    "data['label'] = data['label'].astype(original_label_dtype)\n",
    "\n",
    "#(60%)(20%)(20%)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.4, stratify=data['stratify_col'], random_state=42)\n",
    "validate_data, test_data = train_test_split(temp_data, test_size=0.5, stratify=temp_data['stratify_col'], random_state=42)\n",
    "\n",
    "train_data.drop('stratify_col', axis=1, inplace=True)\n",
    "validate_data.drop('stratify_col', axis=1, inplace=True)\n",
    "test_data.drop('stratify_col', axis=1, inplace=True)\n",
    "\n",
    "print(\"Training size: {}\".format(len(train_data)))\n",
    "print(\"Validation size: {}\".format(len(validate_data)))\n",
    "print(\"Testing size: {}\".format(len(test_data)))\n",
    "\n",
    "display(train_data)\n",
    "display(validate_data)\n",
    "display(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = train_data.reset_index(drop=True)\n",
    "validate_data = validate_data.reset_index(drop=True)\n",
    "test_data = test_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training size: 4200\n",
      "Validation size: 1400\n",
      "Testing size: 1400\n"
     ]
    }
   ],
   "source": [
    "print(\"Training size: {}\".format(len(train_data)))\n",
    "print(\"Validation size: {}\".format(len(validate_data)))\n",
    "print(\"Testing size: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escolhendo a GPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All TF 2.0 model weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the TF 2.0 model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "# tokenizer = BertTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"neuralmind/bert-base-portuguese-cased\")\n",
    "model = BertForSequenceClassification.from_pretrained(\"neuralmind/bert-base-portuguese-cased\", from_tf=True)\n",
    "model.config.num_labels = 1\n",
    "#load no Tokenizador e o modelo BERTimbau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Desabilitando a atualização dos gradientes para acelerar o processamento e diminuir o consumo\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definindo a arquitetura da camada classificadora\n",
    "# composta por várias camadas densas e de ativação para processamento não linear e uma camada Softmax \n",
    "# para obter as probabilidades de cada classe.\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(768, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256, 64),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(64, 2),\n",
    "    nn.Softmax(dim=1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "# Alocando o modelo e o critério de perda na GPU\n",
    "criterion = nn.MSELoss().to(device)\n",
    "\n",
    "# Atualizar apenas os parâmetros da camada classificadora com uma taxa de aprendizado de 0,01.\n",
    "optimizer = optim.SGD(model.classifier.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "  #limpando String\n",
    "  return text.replace('\\n', ' ').replace('\\t', ' ').replace('   ', ' ').replace('  ', ' ')\n",
    " \n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = clean_text(text)\n",
    "    parts = []\n",
    "\n",
    "    text_len = len(text.split(' '))\n",
    "    delta = 300 #numero de palavras\n",
    "    max_parts = 5 #numero maximo de partes a serem divididas\n",
    "    nb_cuts = int(text_len / delta)\n",
    "    nb_cuts = min(nb_cuts, max_parts)\n",
    "    \n",
    "    #Tokenizando o texto\n",
    "    for i in range(nb_cuts + 1):\n",
    "        text_part = ' '.join(text.split(' ')[i * delta: (i + 1) * delta])\n",
    "        parts.append(tokenizer.encode(text_part, return_tensors=\"pt\", max_length=500).to(device))\n",
    "\n",
    "    return parts\n",
    "\n",
    "def testText(text):\n",
    "    text_parts = preprocess_text(text)\n",
    "    overall_output = torch.zeros((1,2)).to(device)\n",
    "    try:\n",
    "        for part in text_parts:\n",
    "            if len(part) > 0:\n",
    "                overall_output += model(part.reshape(1, -1))[0]\n",
    "    except RuntimeError:\n",
    "        print(\"GPU out of memory, skipping this entry.\")\n",
    "\n",
    "    overall_output = F.softmax(overall_output[0], dim=-1)\n",
    "\n",
    "    value, result = overall_output.max(0)\n",
    "\n",
    "    term = \"falso\"\n",
    "    if result.item() == 0:\n",
    "        term = \"verdadeiro\"\n",
    "\n",
    "    print(\"{} : {}%\".format(term, value.item() * 100))\n",
    "    return term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertFakeNewsDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, tokenizer, max_seq_length=512):\n",
    "        self._labels = torch.tensor(df[\"label\"].values, dtype=torch.long)\n",
    "        self._encodings = {\"input_ids\": [],\n",
    "                           \"token_type_ids\": [],\n",
    "                           \"attention_mask\": []}\n",
    "\n",
    "        for txt in df[\"text\"].values:\n",
    "            enc_dict = tokenizer.encode_plus(\n",
    "                text=txt,\n",
    "                add_special_tokens=True,\n",
    "                max_length=max_seq_length,\n",
    "                return_token_type_ids=True,\n",
    "                padding=\"max_length\",\n",
    "                return_attention_mask=True,\n",
    "                return_tensors=\"pt\",\n",
    "                truncation=True,\n",
    "            )\n",
    "            # Verifica se a parte tokenizada excede o limite após adicionar tokens especiais\n",
    "            if len(enc_dict[\"input_ids\"][0]) > max_seq_length:\n",
    "                print(\"Truncamento detectado após adição de tokens especiais!\")\n",
    "\n",
    "            for k, v in enc_dict.items():\n",
    "                self._encodings[k].append(v[0])\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: value[idx] for key, value in self._encodings.items()}\n",
    "        item[\"labels\"] = self._labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self._labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataTK = BertFakeNewsDataset(train_data,tokenizer)\n",
    "validate_dataTK = BertFakeNewsDataset(validate_data,tokenizer)\n",
    "test_dataTK = BertFakeNewsDataset(test_data,tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(labels, predictions),\n",
    "        \"qwk\": cohen_kappa_score(labels, predictions, weights=\"quadratic\"),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_args = TrainingArguments(\n",
    "    output_dir='C:\\TCC',\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    learning_rate=2.5e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=10,\n",
    "    weight_decay=1e-5, #1e-5 ou 5e-5 é um valor padrão 0.01,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_strategy=\"epoch\",\n",
    "    save_steps=1000,\n",
    "    save_total_limit=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=train_args,\n",
    "    train_dataset=train_dataTK,\n",
    "    eval_dataset=validate_dataTK,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mateu\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\transformers\\optimization.py:407: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "  0%|          | 0/2630 [00:00<?, ?it/s]You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|█         | 263/2630 [02:56<17:06,  2.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.6468522548675537, 'eval_accuracy': 0.8728571428571429, 'eval_qwk': 0.7457698012882901, 'eval_runtime': 41.2708, 'eval_samples_per_second': 33.922, 'eval_steps_per_second': 2.132, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 500/2630 [04:58<18:02,  1.97it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6454, 'learning_rate': 2.0247148288973387e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 20%|██        | 526/2630 [05:53<15:20,  2.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.5396915078163147, 'eval_accuracy': 0.9028571428571428, 'eval_qwk': 0.8057487752174615, 'eval_runtime': 41.2793, 'eval_samples_per_second': 33.915, 'eval_steps_per_second': 2.132, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                    \n",
      " 30%|███       | 789/2630 [08:49<13:21,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.47187501192092896, 'eval_accuracy': 0.91, 'eval_qwk': 0.8200348911945643, 'eval_runtime': 41.2803, 'eval_samples_per_second': 33.915, 'eval_steps_per_second': 2.132, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1000/2630 [10:39<13:51,  1.96it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4973, 'learning_rate': 1.549429657794677e-05, 'epoch': 3.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 40%|████      | 1052/2630 [11:47<11:25,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.43971094489097595, 'eval_accuracy': 0.9157142857142857, 'eval_qwk': 0.8314584961445621, 'eval_runtime': 41.2793, 'eval_samples_per_second': 33.915, 'eval_steps_per_second': 2.132, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 50%|█████     | 1315/2630 [15:01<11:39,  1.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4216495156288147, 'eval_accuracy': 0.9235714285714286, 'eval_qwk': 0.8471659382052507, 'eval_runtime': 46.2382, 'eval_samples_per_second': 30.278, 'eval_steps_per_second': 1.903, 'epoch': 5.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 1500/2630 [16:47<09:42,  1.94it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4369, 'learning_rate': 1.0741444866920153e-05, 'epoch': 5.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 60%|██████    | 1578/2630 [18:21<08:38,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.41187021136283875, 'eval_accuracy': 0.9278571428571428, 'eval_qwk': 0.8557354837656508, 'eval_runtime': 47.625, 'eval_samples_per_second': 29.396, 'eval_steps_per_second': 1.848, 'epoch': 6.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 70%|███████   | 1841/2630 [21:17<05:34,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.4060433506965637, 'eval_accuracy': 0.9292857142857143, 'eval_qwk': 0.8585922068594003, 'eval_runtime': 40.4111, 'eval_samples_per_second': 34.644, 'eval_steps_per_second': 2.178, 'epoch': 7.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 2000/2630 [22:37<05:14,  2.01it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.417, 'learning_rate': 5.988593155893536e-06, 'epoch': 7.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 80%|████████  | 2104/2630 [24:09<03:42,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.40299931168556213, 'eval_accuracy': 0.9271428571428572, 'eval_qwk': 0.8543080140794777, 'eval_runtime': 40.6091, 'eval_samples_per_second': 34.475, 'eval_steps_per_second': 2.167, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 90%|█████████ | 2367/2630 [27:03<01:52,  2.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3998693823814392, 'eval_accuracy': 0.9314285714285714, 'eval_qwk': 0.8628764520914401, 'eval_runtime': 40.6481, 'eval_samples_per_second': 34.442, 'eval_steps_per_second': 2.165, 'epoch': 9.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 2500/2630 [28:11<01:05,  2.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.4094, 'learning_rate': 1.2357414448669203e-06, 'epoch': 9.51}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      "100%|██████████| 2630/2630 [29:58<00:00,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.3992252051830292, 'eval_accuracy': 0.9314285714285714, 'eval_qwk': 0.8628764520914401, 'eval_runtime': 40.6671, 'eval_samples_per_second': 34.426, 'eval_steps_per_second': 2.164, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2630/2630 [29:59<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 1799.154, 'train_samples_per_second': 23.344, 'train_steps_per_second': 1.462, 'train_loss': 0.4775258967178403, 'epoch': 10.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2630, training_loss=0.4775258967178403, metrics={'train_runtime': 1799.154, 'train_samples_per_second': 23.344, 'train_steps_per_second': 1.462, 'train_loss': 0.4775258967178403, 'epoch': 10.0})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [02:03<00:00,  2.13it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.397233247756958,\n",
       " 'eval_accuracy': 0.9392857142857143,\n",
       " 'eval_qwk': 0.8785714285714286,\n",
       " 'eval_runtime': 123.873,\n",
       " 'eval_samples_per_second': 33.906,\n",
       " 'eval_steps_per_second': 2.123,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(train_dataTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:40<00:00,  2.16it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.3998693823814392,\n",
       " 'eval_accuracy': 0.9314285714285714,\n",
       " 'eval_qwk': 0.8628764520914401,\n",
       " 'eval_runtime': 41.1637,\n",
       " 'eval_samples_per_second': 34.011,\n",
       " 'eval_steps_per_second': 2.138,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(validate_dataTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:41<00:00,  2.14it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.39862915873527527,\n",
       " 'eval_accuracy': 0.94,\n",
       " 'eval_qwk': 0.8799894684635591,\n",
       " 'eval_runtime': 41.6934,\n",
       " 'eval_samples_per_second': 33.578,\n",
       " 'eval_steps_per_second': 2.111,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataTK) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falso : 84.24559235572815%\n",
      "verdadeiro : 52.21601724624634%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'verdadeiro'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falso = \"\"\"Mais uma pérola da \"senhora que estoca vento\". Em nota, ela sugere que a PF \"tortura\" investigados.  A ex-presidente impeachmada Dilma Rousseff continua falando pelos cotovelos.  (observação: Em seu texto, ela não usou a palavra \"tortura\" [...] mas para quem sabe ler, um pingo é letra!) Durante a última semana, Dilma teve a audácia (a petulância, a ousadia, destemor) de dizer que os investigadores da Polícia Federal estão ameaçando os delatores da Lava-Jato. Dilma também atacou o ministro relator da Lava-Jato, Edson Fachin, e o acusou de abrir as delações de João Santana e Mônica Moura para a imprensa antes sem antes dar acesso dos documentos a seus advogados. Resumindo, Dilma é honesta [...] já Edson Fachin (Ministro do STF) e a Polícia Federal são os \"bandidos da história\" Em uma nota divulgada na última sexta-feira, a \"senhora que estoca vento\" também disse que todos os delatores são mentirosos. abaixo a íntegra da nota: 1. Infelizmente, chega tarde a decisão do relator da Lava Jato no Supremo Tribunal Federal, ministro Edson Fachin, suspendendo o sigilo dos depoimentos de João Santana e Monica Moura. 2. Há semanas, a defesa da presidenta eleita Dilma Rousseff havia feito tal pedido ao Tribunal Superior Eleitoral, a fim de apresentar suas alegações finais ao relator do caso das contas de campanha, ministro Herman Benjamin. 3. A defesa foi prejudicada pela negativa do relator. Não foi possível cotejar os depoimentos prestados pelo casal à Justiça Eleitoral e na Lava Jato. 4. As contradições e falsos testemunhos foram vislumbrados, apesar disso, pelo que foi divulgado amplamente pela imprensa, na velha estratégia do vazamento seletivo dos depoimentos – uma rotina nos últimos tempos. 5. Agora mesmo, os depoimentos são entregues à imprensa, mas não repassados oficialmente à defesa da presidente eleita. 6. Dilma Rousseff, contudo, reitera o que apontou antes: João Santana e Monica Moura prestaram falso testemunho e faltaram com a verdade em seus depoimentos, provavelmente pressionados pelas ameaças dos investigadores. 7. Apesar de tudo, a presidente eleita acredita na Justiça e sabe que a verdade virá à tona e será restabelecida.\"\"\"\n",
    "\n",
    "Verdadeiro = \"\"\"Saúde de Lula é 'excelente', atestam exames feitos hoje\n",
    "\n",
    "O ex-presidente Luiz Inácio Lula da Silva encontra-se em \"excelente condição de saúde e sem qualquer evidência de neoplasia\", diz o boletim assinado pelos médicos Antonio Carlos Onofre de Lira, diretor técnico médico, e Paulo Cesar Ayroza Galvão, diretor clínico do hospital sírio-libanês.\n",
    "\n",
    "Lula foi submetido a exames clínicos, laboratoriais, PET-CT, ressonância nuclear magnética e laringoscopia durante toda a manhã deste sábado, 1. Todos de rotina. Essa rotina vem sendo repetida desde 2011, quando foi detectado um câncer na laringe do ex-presidente, que se submeteu a tratamento e deve fazer o controle por cinco anos. O último exame havia sido realizado em 10 de agosto. As equipes que acompanham o ex-presidente são coordenadas pelos médicos Roberto Kalil Filho e Artur Katz. Lula deixou o hospital sem falar com a imprensa.\n",
    "\"\"\"\n",
    "\n",
    "testText(falso)\n",
    "testText(Verdadeiro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:41<00:00,  2.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.9380530973451328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Obter as previsões do modelo para o conjunto de teste\n",
    "predictions = trainer.predict(test_dataTK).predictions\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Obter os rótulos verdadeiros do conjunto de teste\n",
    "true_labels = test_dataTK._labels.numpy()\n",
    "\n",
    "# Calcular a métrica F1\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
